#+TITLE: How AI can be a force for good

**
#+BEGIN_QUOTE
With distributed agency comes distributed responsibility. Existing ethical frameworks address individual, human responsibility, with the goal of allocating punishment or reward based on the actions and intentions of an individual. They were not developed to deal with distributed
responsibility.
#+END_QUOTE
** https://drive.google.com/drive/u/1/folders/13bwMQfn8RY67-znVdnC7WO6OdcpDtR83
** This seems like an important point: we'll need new (not necessarily "agential") ways to think about ethics.
** It seems useful to apply this in somewhat more general terms about "intelligent systems" â€” or just "systems with emergent properties"; so, if distributed agents produce e.g., environmental degradation, that's not ethical, and the system as a whole "should" find ways to improve its behaviour.  This sort of thing is thought about in Elinor Ostrom's economics.
** A particular concern of Taddeo & Floridi here seems to be "autonomy" of AI, and "self-determination" of humans. But in the case of HCI/HCCC it's not totally clear that either of these criteria apply.  In HCCC it's much closer to anthropotechnics
*** https://www.wired.com/beyond-the-beyond/2015/09/peter-sloterdijk-anthropotechnics/
**
#+BEGIN_QUOTE
Humanity learned this lesson the hard way when it did not regulate the impact of the industrial revolution on labor forces, and also when it recognized too late the environmental impact of massive industrialization and global consumerism.
#+END_QUOTE
**
